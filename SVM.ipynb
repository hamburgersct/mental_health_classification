{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape before drop:  (178, 50)\n",
      "dataframe shape after drop:  (178, 24)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "columns = ['学号', '性别', '生源地', '总分', '幻觉、妄想症状', '自杀意图', '焦虑指标总分', '抑郁指标总分', '偏执指标总分', '自卑指标总分',\n",
    "               '敏感指标总分', '社交恐惧指标总分', '躯体化指标总分', '依赖指标总分', '敌对攻击指标总分', '冲动指标总分', '强迫指标总分',\n",
    "               '网络成瘾指标总分', '自伤行为指标总分', '进食问题指标总分', '睡眠困扰指标总分', '学校适应困难指标总分', '人际关系困扰指标总分',\n",
    "               '学业压力指标总分', '就业压力指标总分', '恋爱困扰指标总分']\n",
    "data = pd.read_csv('student_data.csv', encoding='utf-8')\n",
    "print('dataframe shape before drop: ', data.shape)\n",
    "data.drop(columns=columns, inplace=True)\n",
    "print('dataframe shape after drop: ', data.shape)\n",
    "train_df, test_df = train_test_split(data, test_size=0.3, random_state=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "0    75\n1    27\n3    11\n2    11\nName: 可能问题, dtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['可能问题'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_class_0 = train_df[train_df['可能问题']==0]\n",
    "train_class_1 = train_df[train_df['可能问题']==1]\n",
    "train_class_2 = train_df[train_df['可能问题']==2]\n",
    "train_class_3 = train_df[train_df['可能问题']==3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from textaugment import EDA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "t = EDA(random_state=8)\n",
    "new_text_1 = [t.random_swap(t.random_insertion(t.random_deletion(t.synonym_replacement(sent), p=0.4))) for sent in train_class_1['text']]\n",
    "new_text_2 = [t.random_swap(t.random_insertion(t.random_deletion(t.synonym_replacement(sent), p=0.4))) for sent in train_class_2['text']]\n",
    "new_text_3 = [t.random_swap(t.random_insertion(t.random_deletion(t.synonym_replacement(sent), p=0.4))) for sent in train_class_3['text']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamburger_sct\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\hamburger_sct\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\hamburger_sct\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "new_class_1 = train_class_1\n",
    "new_class_1['text'] = new_text_1\n",
    "train_1 = pd.concat([train_class_1, new_class_1])\n",
    "\n",
    "new_class_2 = train_class_2\n",
    "new_class_2['text'] = new_text_2\n",
    "train_2 = pd.concat([train_class_2, new_class_2])\n",
    "\n",
    "new_class_3 = train_class_3\n",
    "new_class_3['text'] = new_text_3\n",
    "train_3 = pd.concat([train_class_3, new_class_3])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0    75\n1    54\n3    22\n2    22\nName: 可能问题, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train_class_0, train_1, train_2, train_3])\n",
    "train['可能问题'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['幻觉、妄想症状指标标准分', '自杀意图指标标准分', '焦虑指标标准分', '抑郁指标标准分', '偏执指标标准分', '自卑指标标准分',\n",
      "       '敏感指标标准分', '社交恐惧指标标准分', '躯体化指标标准分', '依赖指标标准分', '敌对攻击指标标准分', '冲动指标标准分',\n",
      "       '强迫指标标准分', '网络成瘾指标标准分', '自伤行为指标标准分', '进食问题指标标准分', '睡眠困扰指标标准分',\n",
      "       '学校适应困难指标标准分', '人际关系困扰指标标准分', '学业压力指标标准分', '就业压力指标标准分', '恋爱困扰指标标准分',\n",
      "       '可能问题', 'text'],\n",
      "      dtype='object')\n",
      "(173, 24)\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print(train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Create Function Transformer to use Feature Union\n",
    "def get_numeric_data(x):\n",
    "    return np.array(x.iloc[:, 0:-2])\n",
    "\n",
    "\n",
    "def get_text_data(x):\n",
    "    return x['text'].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def metadata_svm_fu():\n",
    "\n",
    "    y_train = train['可能问题'].tolist()\n",
    "    y_test = test_df['可能问题'].tolist()\n",
    "\n",
    "    transformer_numeric = FunctionTransformer(get_numeric_data)\n",
    "    transformer_text = FunctionTransformer(get_text_data)\n",
    "\n",
    "    # Create a pipeline to concatenate Tfidf Vector and Numeric data\n",
    "    # Use SVM as classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('metadata', FeatureUnion([\n",
    "            ('numeric_feature', Pipeline([\n",
    "                ('selector', transformer_numeric)\n",
    "            ])),\n",
    "            ('text_features', Pipeline([\n",
    "                ('selector', transformer_text),\n",
    "                ('vec', TfidfVectorizer())\n",
    "            ]))\n",
    "        ])),\n",
    "        ('clf', SGDClassifier())\n",
    "    ])\n",
    "\n",
    "    # Grid Search Parameters for SGDClassifer\n",
    "    parameters = {\n",
    "        'clf__alpha': (1e-4, 1e-6),\n",
    "        'metadata__text_features__vec__ngram_range': [(1, 2), (1, 3)],\n",
    "        'metadata__text_features__vec__use_idf': [True, False]\n",
    "    }\n",
    "\n",
    "    # Training config\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "    scoring = {'Accuracy': 'accuracy', 'F1': 'f1_macro'}\n",
    "    refit = 'F1'\n",
    "\n",
    "    gs_clf = GridSearchCV(pipeline, parameters, n_jobs=1, verbose=1, cv=kfold, scoring=scoring, refit=refit)\n",
    "    gs_clf.fit(train, y_train)\n",
    "\n",
    "    predicted = gs_clf.predict(test_df)\n",
    "\n",
    "    print(metrics.classification_report(y_test, predicted))\n",
    "    print(metrics.confusion_matrix(y_test, predicted))\n",
    "    print(\"precision: \", str(metrics.precision_score(y_test, predicted, average='macro')))\n",
    "    print(\"accuracy: \", str(metrics.accuracy_score(y_test, predicted)))\n",
    "    print(\"F1 score: \", str(metrics.f1_score(y_test, predicted, average='macro')))\n",
    "    print(\"recall: \", str(metrics.recall_score(y_test, predicted, average='macro')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79        31\n",
      "           1       0.36      0.24      0.29        17\n",
      "           2       0.14      0.25      0.18         4\n",
      "           3       0.17      0.50      0.25         2\n",
      "\n",
      "    accuracy                           0.56        54\n",
      "   macro avg       0.37      0.44      0.38        54\n",
      "weighted avg       0.59      0.56      0.56        54\n",
      "\n",
      "[[24  4  3  0]\n",
      " [ 6  4  2  5]\n",
      " [ 0  3  1  0]\n",
      " [ 0  0  1  1]]\n",
      "precision:  0.3682900432900433\n",
      "accuracy:  0.5555555555555556\n",
      "F1 score:  0.3761044283585267\n",
      "recall:  0.4398719165085389\n"
     ]
    }
   ],
   "source": [
    "metadata_svm_fu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def standard_svm():\n",
    "\n",
    "    X_train = train['text'].tolist()\n",
    "    X_test = test_df['text'].tolist()\n",
    "    y_train = train['可能问题'].tolist()\n",
    "    y_test = test_df['可能问题'].tolist()\n",
    "\n",
    "    pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier()),\n",
    "                         ])\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 2), (1, 3)],\n",
    "        'clf__alpha': (1e-4, 1e-6)\n",
    "    }\n",
    "\n",
    "    # Training config\n",
    "    kfold = StratifiedKFold(n_splits=5)\n",
    "    scoring = {'Accuracy': 'accuracy', 'F1': 'f1_macro'}\n",
    "    refit = 'F1'\n",
    "\n",
    "    gs_clf = GridSearchCV(pipeline, parameters, n_jobs=1, verbose=1, cv=kfold, scoring=scoring, refit=refit)\n",
    "    gs_clf.fit(X_train, y_train)\n",
    "\n",
    "    predicted = gs_clf.predict(X_test)\n",
    "\n",
    "    print(metrics.classification_report(y_test, predicted))\n",
    "    print(metrics.confusion_matrix(y_test, predicted))\n",
    "    print(\"precision: \", str(metrics.precision_score(y_test, predicted, average='macro')))\n",
    "    print(\"accuracy: \", str(metrics.accuracy_score(y_test, predicted)))\n",
    "    print(\"F1 score: \", str(metrics.f1_score(y_test, predicted, average='macro')))\n",
    "    print(\"recall: \", str(metrics.recall_score(y_test, predicted, average='macro')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73        31\n",
      "           1       0.00      0.00      0.00        17\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.57        54\n",
      "   macro avg       0.14      0.25      0.18        54\n",
      "weighted avg       0.33      0.57      0.42        54\n",
      "\n",
      "[[31  0  0  0]\n",
      " [17  0  0  0]\n",
      " [ 4  0  0  0]\n",
      " [ 2  0  0  0]]\n",
      "precision:  0.14351851851851852\n",
      "accuracy:  0.5740740740740741\n",
      "F1 score:  0.1823529411764706\n",
      "recall:  0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamburger_sct\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hamburger_sct\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hamburger_sct\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hamburger_sct\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "standard_svm()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "nlp_env",
   "language": "python",
   "display_name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}